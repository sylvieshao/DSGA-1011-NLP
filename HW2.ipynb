{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import itertools\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms6771/.conda/envs/nlp/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/hw2_data/'\n",
    "snli_train = pd.read_csv(path + 'snli_train.tsv', sep='\\t')\n",
    "snli_val = pd.read_csv(path + 'snli_val.tsv', sep='\\t')\n",
    "mnli_train = pd.read_csv(path + 'mnli_train.tsv', sep='\\t')\n",
    "mnli_val = pd.read_csv(path + 'mnli_val.tsv', sep='\\t')\n",
    "\n",
    "label_dict = {0: 'neutral', 1: 'entailment', 2: 'contradiction'}\n",
    "genre_dict = {0: 'telephone', 1: 'fiction', 2: 'slate', 3: 'government', 4: 'travel'}\n",
    "\n",
    "for idx, label in label_dict.items():\n",
    "    snli_train['label'].loc[snli_train['label'] == label] = idx\n",
    "    snli_val['label'].loc[snli_val['label'] == label] = idx\n",
    "    mnli_train['label'].loc[mnli_train['label'] == label] = idx\n",
    "    mnli_val['label'].loc[mnli_val['label'] == label] = idx\n",
    "\n",
    "for idx, genre in genre_dict.items():\n",
    "    mnli_train['genre'].loc[mnli_train['genre'] == genre] = idx\n",
    "    mnli_val['genre'].loc[mnli_val['genre'] == genre] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load Fasttext Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_path = os.getcwd() + '/wiki-news-300d-1M.vec'\n",
    "words_to_load = 50000\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "fin = io.open(ft_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "\n",
    "n, d = map(int, fin.readline().split())\n",
    "vocab_size = words_to_load + 2\n",
    "embedding_dim = d\n",
    "\n",
    "embedding_mat = np.zeros((vocab_size, embedding_dim))\n",
    "token2id = {}\n",
    "id2token = {}\n",
    "all_tokens = []\n",
    "\n",
    "for i, line in enumerate(fin):\n",
    "    if i >= words_to_load:\n",
    "        break\n",
    "    s = line.rstrip().split(' ')\n",
    "    embedding_mat[i+2, :] = np.asarray(s[1:])\n",
    "    token2id[s[0]] = i+2\n",
    "    id2token[i+2] = s[0]\n",
    "    all_tokens.append(s[0])\n",
    "\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    id2token[PAD_IDX] = '<pad>'\n",
    "    id2token[UNK_IDX] = '<unk>'\n",
    "    embedding_mat[0, :] = np.zeros((1,d))\n",
    "    #generate normal dist 1d array for UNK token\n",
    "    embedding_mat[1, :] = np.random.normal(size=d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for i in tokens_data:\n",
    "        tokens = i.split()\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent1_indices = token2index_dataset(snli_train['sentence1'])\n",
    "train_sent2_indices = token2index_dataset(snli_train['sentence2'])\n",
    "val_sent1_indices = token2index_dataset(snli_val['sentence1'])\n",
    "val_sent2_indices = token2index_dataset(snli_val['sentence2'])\n",
    "train_y = [i for i in snli_train['label']]\n",
    "val_y = [i for i in snli_val['label']]\n",
    "\n",
    "mnli_train_sent1_indices = token2index_dataset(mnli_train['sentence1'])\n",
    "mnli_train_sent2_indices = token2index_dataset(mnli_train['sentence2'])\n",
    "mnli_val_sent1_indices = token2index_dataset(mnli_val['sentence1'])\n",
    "mnli_val_sent2_indices = token2index_dataset(mnli_val['sentence2'])\n",
    "mnli_train_y = [i for i in mnli_train['label']]\n",
    "mnli_train_genre = [i for i in mnli_train['genre']]\n",
    "mnli_val_y = [i for i in mnli_val['label']]\n",
    "mnli_val_genre = [i for i in mnli_val['genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max sent length = 99% length in the training set\n",
    "# Tend to have longer premise sentences than hypothesis sentences. \n",
    "# Define two separate \"max lengths\" to reflect this.\n",
    "sent_length_1 = [len(train_sent1_indices[i]) for i in range(len(train_sent1_indices))]\n",
    "sent_length_2 = [len(train_sent2_indices[i]) for i in range(len(train_sent2_indices))]\n",
    "MAX_SENTENCE_LENGTH_1 = int(np.percentile(sent_length_1,99))\n",
    "MAX_SENTENCE_LENGTH_2 = int(np.percentile(sent_length_2,99))\n",
    "\n",
    "mnli_sent_length_1 = [len(mnli_train_sent1_indices[i]) for i in range(len(mnli_train_sent1_indices))]\n",
    "mnli_sent_length_2 = [len(mnli_train_sent2_indices[i]) for i in range(len(mnli_train_sent2_indices))]\n",
    "mnli_MAX_SENTENCE_LENGTH_1 = int(np.percentile(mnli_sent_length_1,99))\n",
    "mnli_MAX_SENTENCE_LENGTH_2 = int(np.percentile(mnli_sent_length_2,99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Loader__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnliDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list_1, data_list_2, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list_1: list of sentence 1 tokens \n",
    "        @param data_list_2: list of sentence 2 tokens\n",
    "        @param target_list: list of review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list_1 = data_list_1\n",
    "        self.data_list_2 = data_list_2\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list_1) == len(self.target_list))\n",
    "        assert (len(self.data_list_2) == len(self.target_list))\n",
    "        assert (len(self.data_list_1) == len(self.data_list_2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_1 = self.data_list_1[key][:MAX_SENTENCE_LENGTH_1]\n",
    "        token_idx_2 = self.data_list_2[key][:MAX_SENTENCE_LENGTH_2]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx_1, len(token_idx_1), token_idx_2, len(token_idx_2), label]\n",
    "\n",
    "def Snil_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_1 = []\n",
    "    data_list_2 = []\n",
    "    label_list = []\n",
    "    length_list_1 = []\n",
    "    length_list_2 = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list_1.append(datum[1])\n",
    "        length_list_2.append(datum[3])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH_1-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0).tolist()\n",
    "        padded_vec_2 = np.pad(np.array(datum[2]), \n",
    "                        pad_width=((0,MAX_SENTENCE_LENGTH_2-datum[3])), \n",
    "                        mode=\"constant\", constant_values=0).tolist()\n",
    "        data_list_1.append(padded_vec_1)\n",
    "        data_list_2.append(padded_vec_2)\n",
    "    return [torch.from_numpy(np.array(data_list_1)), torch.LongTensor(length_list_1), \n",
    "            torch.from_numpy(np.array(data_list_2)), torch.LongTensor(length_list_2),\n",
    "            torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = SnliDataset(train_sent1_indices, train_sent2_indices, train_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=Snil_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SnliDataset(val_sent1_indices, val_sent2_indices, val_y)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         collate_fn=Snil_collate_func,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnliDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list_1, data_list_2, target_list, genre_list):\n",
    "        \"\"\"\n",
    "        @param data_list_1: list of sentence 1 tokens \n",
    "        @param data_list_2: list of sentence 2 tokens\n",
    "        @param target_list: list of review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list_1 = data_list_1\n",
    "        self.data_list_2 = data_list_2\n",
    "        self.target_list = target_list\n",
    "        self.genre_list = genre_list\n",
    "        assert (len(self.data_list_1) == len(self.target_list))\n",
    "        assert (len(self.data_list_2) == len(self.target_list))\n",
    "        assert (len(self.data_list_1) == len(self.data_list_2))\n",
    "        assert (len(self.data_list_2) == len(self.genre_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list_1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_1 = self.data_list_1[key][:mnli_MAX_SENTENCE_LENGTH_1]\n",
    "        token_idx_2 = self.data_list_2[key][:mnli_MAX_SENTENCE_LENGTH_2]\n",
    "        label = self.target_list[key]\n",
    "        genre = self.genre_list[key]\n",
    "        return [token_idx_1, len(token_idx_1), token_idx_2, len(token_idx_2), label, genre]\n",
    "\n",
    "def Mnil_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list_1 = []\n",
    "    data_list_2 = []\n",
    "    label_list = []\n",
    "    length_list_1 = []\n",
    "    length_list_2 = []\n",
    "    genre_list = []\n",
    "    \n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list_1.append(datum[1])\n",
    "        length_list_2.append(datum[3])\n",
    "        genre_list.append(datum[5])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,mnli_MAX_SENTENCE_LENGTH_1-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0).tolist()\n",
    "        padded_vec_2 = np.pad(np.array(datum[2]), \n",
    "                        pad_width=((0,mnli_MAX_SENTENCE_LENGTH_2-datum[3])), \n",
    "                        mode=\"constant\", constant_values=0).tolist()\n",
    "        data_list_1.append(padded_vec_1)\n",
    "        data_list_2.append(padded_vec_2)\n",
    "    return [torch.from_numpy(np.array(data_list_1)), torch.LongTensor(length_list_1), \n",
    "            torch.from_numpy(np.array(data_list_2)), torch.LongTensor(length_list_2),\n",
    "            torch.LongTensor(label_list), torch.LongTensor(genre_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "BATCH_SIZE = 5000\n",
    "mnli_train_dataset = MnliDataset(mnli_train_sent1_indices, mnli_train_sent2_indices, mnli_train_y, mnli_train_genre)\n",
    "mnli_train_loader = torch.utils.data.DataLoader(dataset=mnli_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=Mnil_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "mnli_val_dataset = MnliDataset(mnli_val_sent1_indices, mnli_val_sent2_indices, mnli_val_y, mnli_val_genre)\n",
    "mnli_val_loader = torch.utils.data.DataLoader(dataset=mnli_val_dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         collate_fn=Mnil_collate_func,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, linear_dim, concat):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_mat), freeze = True)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, num_layers, bidirectional = True, batch_first = True)\n",
    "        self.linear_1 = nn.Linear(hidden_size * 2, linear_dim)\n",
    "        self.linear_1_mult = nn.Linear(hidden_size, linear_dim)\n",
    "        self.leaky_relu = nn.LeakyReLU(inplace=True)\n",
    "        self.linear_2 = nn.Linear(linear_dim, num_classes)\n",
    "        self.concat = concat\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        if use_gpu:\n",
    "            self.hidden = torch.randn(num_layers * 2, batch_size, self.hidden_size).cuda()\n",
    "        else:\n",
    "            self.hidden = torch.randn(num_layers * 2, batch_size, self.hidden_size)\n",
    "        return self.hidden\n",
    "\n",
    "    def forward(self, x1, lengths_1, x2, lengths_2):\n",
    "        # reset hidden state\n",
    "        batch_size, seq_len_1 = x1.size()\n",
    "        batch_size, seq_len_2 = x2.size()\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        # Compute sorted sequence lengths\n",
    "        _, idx_sort_1 = torch.sort(lengths_1, dim=0, descending=True)\n",
    "        _, idx_sort_2 = torch.sort(lengths_2, dim=0, descending=True)\n",
    "        _, idx_unsort_1 = torch.sort(idx_sort_1, dim=0)\n",
    "        _, idx_unsort_2 = torch.sort(idx_sort_2, dim=0)\n",
    "        \n",
    "        # get embedding of characters\n",
    "        embed_1 = self.embedding(x1).float()\n",
    "        embed_2 = self.embedding(x2).float()\n",
    "        \n",
    "        # Sort embedding and length\n",
    "        embed_1 = embed_1.index_select(0, idx_sort_1)\n",
    "        embed_2 = embed_2.index_select(0, idx_sort_2)\n",
    "        lengths_1 = lengths_1.index_select(0, idx_sort_1)\n",
    "        lengths_2 = lengths_2.index_select(0, idx_sort_2)\n",
    "        \n",
    "        # Pack padded sequence\n",
    "        if use_gpu:\n",
    "            embed_1 = torch.nn.utils.rnn.pack_padded_sequence(embed_1, lengths_1.cpu().numpy(), batch_first=True).cuda()\n",
    "            embed_2 = torch.nn.utils.rnn.pack_padded_sequence(embed_2, lengths_2.cpu().numpy(), batch_first=True).cuda()\n",
    "        else:\n",
    "            embed_1 = torch.nn.utils.rnn.pack_padded_sequence(embed_1, lengths_1.cpu().numpy(), batch_first=True)\n",
    "            embed_2 = torch.nn.utils.rnn.pack_padded_sequence(embed_2, lengths_2.cpu().numpy(), batch_first=True)\n",
    "        \n",
    "        # fprop through GRU\n",
    "        rnn_out_1, hn_1 = self.rnn(embed_1, self.hidden)\n",
    "        rnn_out_2, hn_2 = self.rnn(embed_2, self.hidden)\n",
    "        \n",
    "        # Sum two bidirectional hidden states over direction\n",
    "        hn_1 = torch.sum(hn_1, dim=0)\n",
    "        hn_2 = torch.sum(hn_2, dim=0)        \n",
    "        \n",
    "        # Unsort last hidden unit\n",
    "        hn_1 = hn_1.index_select(0, idx_unsort_1)\n",
    "        hn_2 = hn_2.index_select(0, idx_unsort_2)\n",
    "        \n",
    "        # Concat two sentence vectors\n",
    "        if self.concat == 'Concatenation':\n",
    "            hn_concat = torch.cat((hn_1, hn_2), 1)\n",
    "            out = self.linear_1(hn_concat)\n",
    "            out = self.leaky_relu(out)\n",
    "            logits = self.linear_2(out)\n",
    "        else:\n",
    "            hn_mult = hn_1 * hn_2\n",
    "            out = self.linear_1_mult(hn_mult)\n",
    "            out = self.leaky_relu(out)\n",
    "            logits = self.linear_2(out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20], Step: [1001/3125], Training Loss: 1.0279985666275024, Train Acc: 58.2, Validation Acc: 57.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-13ff044b6e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0msent_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-9fb2d9623032>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, lengths_1, x2, lengths_2)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# fprop through GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrnn_out_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mrnn_out_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "emb_size = embedding_dim\n",
    "hidden_size_ls = [100, 200, 300, 400, 500]\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "linear_dim = 50\n",
    "concat_ls = ['Concatenation', 'Multiplication']\n",
    "learning_rate_ls = [1e-2, 1e-3, 1e-4]\n",
    "num_epochs = 20 # number epoch to train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for sent_1, len_1, sent_2, len_2, label in loader:\n",
    "        if use_gpu:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda()\n",
    "        else:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1, len_1, sent_2, len_2, label\n",
    "        outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += label_batch.size(0)\n",
    "        correct += predicted.eq(label_batch.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "\n",
    "for i in itertools.product(hidden_size_ls, concat_ls, learning_rate_ls):\n",
    "    hidden_size, concat, learning_rate = i[0], i[1], i[2]\n",
    "    loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    best_val_acc = None\n",
    "    init_learning_rate = learning_rate\n",
    "    save_path = os.getcwd() + '/SnilRNN (Hidden Size-{} | {} | LR-{}).pt'.format(hidden_size, concat, init_learning_rate)\n",
    "\n",
    "    model = RNN(emb_size, hidden_size, num_layers, num_classes, linear_dim, concat)\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (sent_1, len_1, sent_2, len_2, label) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            if use_gpu:\n",
    "                sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda()\n",
    "            else:\n",
    "                sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1, len_1, sent_2, len_2, label\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i > 0 and i % 1000 == 0:\n",
    "                train_acc = test_model(train_loader, model)\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                loss_ = loss.item()\n",
    "                loss_hist.append(loss_)\n",
    "                train_acc_hist.append(train_acc)\n",
    "                val_acc_hist.append(val_acc)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Loss: {}, Train Acc: {}, Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss_, train_acc, val_acc))\n",
    "\n",
    "                if not best_val_acc or val_acc > best_val_acc:\n",
    "                    torch.save({\n",
    "                                'epoch': epoch,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'train_loss': loss_,\n",
    "                                'best_val_accuracy': best_val_acc\n",
    "                                }, save_path)\n",
    "                    best_val_acc = val_acc\n",
    "                # else:\n",
    "                #     # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "                #     learning_rate /= 4.0\n",
    "            \n",
    "    fig = plt.figure(figsize=(13,3.5))\n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax1.plot(loss_hist, \n",
    "             label = 'RNN Hidden Size: {} | {} | LR: {}'.format(hidden_size, concat, init_learning_rate))\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Train Loss')\n",
    "    ax1.set_title('Train Loss')\n",
    "    ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax2.plot(train_acc_hist)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Train Accuracy')\n",
    "    ax2.set_title('Train Accuracy')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,3,3)\n",
    "    ax2.plot(val_acc_hist)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Validation Accuracy')\n",
    "    ax2.set_title('Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('RNN (Hidden Size-{} | {} | LR-{}).png'.format(hidden_size, concat, init_learning_rate), \n",
    "                dpi = 100, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3 Correct and 3 Incorrect Predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ms6771/HW2/RNN Results/SnilRNN (Hidden Size-300 | Concatenation | LR-0.001).pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(50002, 300)\n",
       "  (rnn): GRU(300, 300, batch_first=True, bidirectional=True)\n",
       "  (linear_1): Linear(in_features=600, out_features=50, bias=True)\n",
       "  (linear_1_mult): Linear(in_features=300, out_features=50, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.01, inplace)\n",
       "  (linear_2): Linear(in_features=50, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_path = os.getcwd() + '/RNN Results/'\n",
    "config = []\n",
    "best_val_acc = []\n",
    "train_loss = []\n",
    "\n",
    "for i in glob.glob(os.path.join(RNN_path, '*.pt')):\n",
    "    checkpoint = torch.load(i)\n",
    "    config.append(i)\n",
    "    \n",
    "    if not checkpoint['best_val_accuracy']: best = 0\n",
    "    else: best = checkpoint['best_val_accuracy']\n",
    "    best_val_acc.append(best)\n",
    "    train_loss.append(checkpoint['train_loss'])\n",
    "\n",
    "best_idx = np.argmax(best_val_acc)\n",
    "best_checkpoint = torch.load(config[best_idx])\n",
    "print(config[best_idx])\n",
    "\n",
    "model = RNN(emb_size = 300, hidden_size = 300, num_layers = 1, num_classes = 3, linear_dim = 50, concat = 'Concatenation')\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = next(iter(val_loader))\n",
    "if use_gpu:\n",
    "    sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1_batch.cuda(), len_1_batch.cuda(), sent_2_batch.cuda(), len_2_batch.cuda(), label_batch.cuda()\n",
    "        \n",
    "outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "predicted = outputs.max(1, keepdim=True)[1]\n",
    "correct = predicted.eq(label_batch.view_as(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Correct Predictions:\n",
      "Sentence 1: Two girls laying in the grass smile as their picture is taken . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: The girls are sisters . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: neutral\n",
      "Predicted: neutral\n",
      "\n",
      "Three Correct Predictions:\n",
      "Sentence 1: A man with a mustache who is wearing white and beige carefully <unk> a sand castle . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A man building a sand castle <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: entailment\n",
      "Predicted: entailment\n",
      "\n",
      "Three Correct Predictions:\n",
      "Sentence 1: The view of a man with a shaved head and blue shirt through a <unk> fence . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A man with a shaved head behind a <unk> fence . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: entailment\n",
      "Predicted: entailment\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: A little girl offers a ball to an upset toddler on a grassy field while a man in <unk> shorts stands behind them . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A man watches two children on a grassy field . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: entailment\n",
      "Predicted: contradiction\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: A man with a beard , curly hair and a beard wearing a green shirt and navy blue jacket standing still looking through his red sunglasses . <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A man is <unk> down . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: contradiction\n",
      "Predicted: entailment\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: <unk> flower cart vendor . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: <unk> vendor by the curb . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: neutral\n",
      "Predicted: entailment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_idx = correct.eq(1).nonzero()[:,0][0:3]\n",
    "incorrect_idx = correct.eq(0).nonzero()[:,0][0:3]\n",
    "correct_dict = {}\n",
    "incorrect_dict = {}\n",
    "\n",
    "for i in correct_idx:\n",
    "    words = []\n",
    "    for j in sent_1_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    correct_dict[i.item()] = [sent]\n",
    "    \n",
    "    words = []\n",
    "    for j in sent_2_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    correct_dict[i.item()].append(sent)\n",
    "    \n",
    "    correct_dict[i.item()].append(\"Label: {}\".format(label_dict[label_batch[i].item()]))\n",
    "    correct_dict[i.item()].append(\"Predicted: {}\".format(label_dict[predicted.view(label_batch.size())[i].item()]))\n",
    "      \n",
    "for i in correct_dict.keys():\n",
    "    print(\"Three Correct Predictions:\\nSentence 1: {}\\nSentence 2: {}\\n{}\\n{}\\n\".format(correct_dict[i][0], correct_dict[i][1], correct_dict[i][2], correct_dict[i][3]))\n",
    "    \n",
    "    \n",
    "for i in incorrect_idx:\n",
    "    words = []\n",
    "    for j in sent_1_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    incorrect_dict[i.item()] = [sent]\n",
    "    \n",
    "    words = []\n",
    "    for m in sent_2_batch[i]:\n",
    "        words.append(id2token[m.item()])\n",
    "    sent = ' '.join(words)\n",
    "    incorrect_dict[i.item()].append(sent)\n",
    "\n",
    "    incorrect_dict[i.item()].append(\"Label: {}\".format(label_dict[label_batch[i].item()]))\n",
    "    incorrect_dict[i.item()].append(\"Predicted: {}\".format(label_dict[predicted.view(label_batch.size())[i].item()]))\n",
    "      \n",
    "for i in incorrect_dict.keys():\n",
    "    print(\"Three Incorrect Predictions:\\nSentence 1: {}\\nSentence 2: {}\\n{}\\n{}\\n\".format(incorrect_dict[i][0], incorrect_dict[i][1], incorrect_dict[i][2], incorrect_dict[i][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate on MNLI Validation Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnli_test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    for sent_1, len_1, sent_2, len_2, label, genre in loader:\n",
    "        if use_gpu:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch, genre_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda(), genre.cuda()\n",
    "        else:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch, genre_batch = sent_1, len_1, sent_2, len_2, label, genre\n",
    "        outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        genre_acc = {}\n",
    "        for i in genre_batch.unique():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            total = genre_batch.eq(i).sum().item()\n",
    "            genre_id = genre_batch.eq(i).nonzero().view(total)\n",
    "            correct += predicted[genre_id].eq(label_batch[genre_id].view_as(predicted[genre_id])).sum().item()\n",
    "            genre_acc[genre_dict[i.item()]] = 100 * correct / total\n",
    "    return genre_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'telephone': 49.75124378109453,\n",
       " 'fiction': 48.34170854271357,\n",
       " 'slate': 46.706586826347305,\n",
       " 'government': 50.39370078740158,\n",
       " 'travel': 47.45417515274949}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_test_model(mnli_val_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, kernel_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embedding_mat), freeze = True)\n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size, padding=1)\n",
    "        self.linear = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x1, lengths_1, x2, lengths_2):\n",
    "        batch_size, seq_len_1 = x1.size()\n",
    "        batch_size, seq_len_2 = x2.size()\n",
    "\n",
    "        embed_1 = self.embedding(x1).float()\n",
    "        embed_2 = self.embedding(x2).float()\n",
    "        \n",
    "        hidden_1 = self.conv1(embed_1.transpose(1,2)).transpose(1,2)\n",
    "        hidden_2 = self.conv1(embed_2.transpose(1,2)).transpose(1,2)\n",
    "        \n",
    "        hidden_1 = F.relu(hidden_1.contiguous().view(-1, hidden_1.size(-1))).view(batch_size, hidden_1.size(1), hidden_1.size(-1))\n",
    "        hidden_2 = F.relu(hidden_2.contiguous().view(-1, hidden_2.size(-1))).view(batch_size, hidden_2.size(1), hidden_2.size(-1))\n",
    "\n",
    "        hidden_1 = self.conv2(hidden_1.transpose(1,2)).transpose(1,2)\n",
    "        hidden_2 = self.conv2(hidden_2.transpose(1,2)).transpose(1,2)\n",
    "        \n",
    "        hidden_1 = F.relu(hidden_1.contiguous().view(-1, hidden_1.size(-1))).view(batch_size, hidden_1.size(1), hidden_1.size(-1))\n",
    "        hidden_2 = F.relu(hidden_2.contiguous().view(-1, hidden_2.size(-1))).view(batch_size, hidden_2.size(1), hidden_2.size(-1))\n",
    "\n",
    "        hidden_1 = torch.max(hidden_1, dim=1, keepdim=False)[0]\n",
    "        hidden_2 = torch.max(hidden_2, dim=1, keepdim=False)[0]\n",
    "        \n",
    "        hidden_concat = torch.cat((hidden_1, hidden_2), 1)\n",
    "        logits = self.linear(hidden_concat)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20], Step: [1001/3125], Training Loss: 1.0018014907836914, Train Acc: 56.846, Validation Acc: 54.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8e52346a98a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0msent_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-3798772ad605>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, lengths_1, x2, lengths_2)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mhidden_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mhidden_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mhidden_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "emb_size = embedding_dim\n",
    "hidden_size_ls = [200, 300, 400, 500]\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "kernel_size_ls = [4, 5]\n",
    "learning_rate_ls = [1e-2, 1e-3,1e-4]\n",
    "num_epochs = 20 # number epoch to train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for sent_1, len_1, sent_2, len_2, label in loader:\n",
    "        if use_gpu:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda()\n",
    "        else:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1, len_1, sent_2, len_2, label\n",
    "        outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += label_batch.size(0)\n",
    "        correct += predicted.eq(label_batch.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "for i in itertools.product(hidden_size_ls, kernel_size_ls, learning_rate_ls):\n",
    "    hidden_size, kernel_size, learning_rate = i[0], i[1], i[2]\n",
    "    loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    best_val_acc = None\n",
    "    init_learning_rate = learning_rate\n",
    "    save_path = os.getcwd() + '/CNN Results/SnilCNN(Hidden Size-{} | Kernel Size-{} | LR-{}).pt'.format(hidden_size, kernel_size, init_learning_rate)\n",
    "    model = CNN(emb_size, hidden_size, num_layers, num_classes, kernel_size)\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (sent_1, len_1, sent_2, len_2, label) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            if use_gpu:\n",
    "                sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda()\n",
    "            else:\n",
    "                sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1, len_1, sent_2, len_2, label\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i > 0 and i % 1000 == 0:\n",
    "                train_acc = test_model(train_loader, model)\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                loss_ = loss.item()\n",
    "                loss_hist.append(loss_)\n",
    "                train_acc_hist.append(train_acc)\n",
    "                val_acc_hist.append(val_acc)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Loss: {}, Train Acc: {}, Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss_, train_acc, val_acc))\n",
    "\n",
    "                if not best_val_acc or val_acc > best_val_acc:\n",
    "                    torch.save({\n",
    "                                'epoch': epoch,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'train_loss': loss_,\n",
    "                                'best_val_accuracy': best_val_acc\n",
    "                                }, save_path)\n",
    "                    best_val_acc = val_acc\n",
    "                # else:\n",
    "                #     # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "                #     learning_rate /= 4.0\n",
    "                    \n",
    "    fig = plt.figure(figsize=(13,3.5))\n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax1.plot(loss_hist, \n",
    "             label = 'CNN Hidden: {} | Kernel: {} | LR: {}'.format(hidden_size, kernel_size, init_learning_rate))\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Train Loss')\n",
    "    ax1.set_title('Train Loss')\n",
    "    ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax2.plot(train_acc_hist)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Train Accuracy')\n",
    "    ax2.set_title('Train Accuracy')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,3,3)\n",
    "    ax2.plot(val_acc_hist)\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Validation Accuracy')\n",
    "    ax2.set_title('Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('CNN (Hidden Size-{} | Kernel Size-{} | LR-{}).png'.format(hidden_size, kernel_size, init_learning_rate), \n",
    "                dpi = 100, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3 Correct and 3 Incorrect Predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ms6771/HW2/CNN Results/SnilCNN(Hidden Size-400 | Kernel Size-3 | LR-0.001).pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(50002, 300)\n",
       "  (conv1): Conv1d(300, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (linear): Linear(in_features=800, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_path = os.getcwd() + '/CNN Results/'\n",
    "config = []\n",
    "best_val_acc = []\n",
    "train_loss = []\n",
    "\n",
    "for i in glob.glob(os.path.join(CNN_path, '*.pt')):\n",
    "    checkpoint = torch.load(i)\n",
    "    config.append(i)\n",
    "    \n",
    "    if not checkpoint['best_val_accuracy']: best = 0\n",
    "    else: best = checkpoint['best_val_accuracy']\n",
    "    best_val_acc.append(best)\n",
    "    train_loss.append(checkpoint['train_loss'])\n",
    "\n",
    "best_idx = np.argmax(best_val_acc)\n",
    "best_checkpoint = torch.load(config[best_idx])\n",
    "print(config[best_idx])\n",
    "\n",
    "model = CNN(emb_size = 300, hidden_size = 400, num_layers = 1, num_classes = 3, kernel_size = 3)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = next(iter(val_loader))\n",
    "if use_gpu:\n",
    "    sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch = sent_1_batch.cuda(), len_1_batch.cuda(), sent_2_batch.cuda(), len_2_batch.cuda(), label_batch.cuda()\n",
    "        \n",
    "outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "predicted = outputs.max(1, keepdim=True)[1]\n",
    "correct = predicted.eq(label_batch.view_as(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Correct Predictions:\n",
      "Sentence 1: Two asian men in a wood shop . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: There are two asian men in that wood shop . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: entailment\n",
      "Predicted: entailment\n",
      "\n",
      "Three Correct Predictions:\n",
      "Sentence 1: A silhouette at the bottom of an escalator . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: The <unk> is creeping out the children . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: neutral\n",
      "Predicted: neutral\n",
      "\n",
      "Three Correct Predictions:\n",
      "Sentence 1: A black and white dog prepares to catch a <unk> . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A black and white cat prepares to catch a <unk> . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: contradiction\n",
      "Predicted: contradiction\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: A family holding hands in the snow are behind a man and his son , whom is wearing a blue jacket . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: A family enjoy the beach on a summer day . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: contradiction\n",
      "Predicted: neutral\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: Two women , one walking her dog the other pushing a <unk> . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Sentence 2: There is a snowstorm . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: contradiction\n",
      "Predicted: neutral\n",
      "\n",
      "Three Incorrect Predictions:\n",
      "Sentence 1: Two men on a basketball court one in white and red the other in blue , the player in white is throwing the ball in while teammates look on . <pad> <pad> <pad> <pad>\n",
      "Sentence 2: The men are playing basketball . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Label: entailment\n",
      "Predicted: contradiction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_idx = correct.eq(1).nonzero()[:,0][0:3]\n",
    "incorrect_idx = correct.eq(0).nonzero()[:,0][0:3]\n",
    "correct_dict = {}\n",
    "incorrect_dict = {}\n",
    "\n",
    "for i in correct_idx:\n",
    "    words = []\n",
    "    for j in sent_1_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    correct_dict[i.item()] = [sent]\n",
    "    \n",
    "    words = []\n",
    "    for j in sent_2_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    correct_dict[i.item()].append(sent)\n",
    "    \n",
    "    correct_dict[i.item()].append(\"Label: {}\".format(label_dict[label_batch[i].item()]))\n",
    "    correct_dict[i.item()].append(\"Predicted: {}\".format(label_dict[predicted.view(label_batch.size())[i].item()]))\n",
    "      \n",
    "for i in correct_dict.keys():\n",
    "    print(\"Three Correct Predictions:\\nSentence 1: {}\\nSentence 2: {}\\n{}\\n{}\\n\".format(correct_dict[i][0], correct_dict[i][1], correct_dict[i][2], correct_dict[i][3]))\n",
    "    \n",
    "    \n",
    "for i in incorrect_idx:\n",
    "    words = []\n",
    "    for j in sent_1_batch[i]:\n",
    "        words.append(id2token[j.item()])\n",
    "    sent = ' '.join(words)\n",
    "    incorrect_dict[i.item()] = [sent]\n",
    "    \n",
    "    words = []\n",
    "    for m in sent_2_batch[i]:\n",
    "        words.append(id2token[m.item()])\n",
    "    sent = ' '.join(words)\n",
    "    incorrect_dict[i.item()].append(sent)\n",
    "\n",
    "    incorrect_dict[i.item()].append(\"Label: {}\".format(label_dict[label_batch[i].item()]))\n",
    "    incorrect_dict[i.item()].append(\"Predicted: {}\".format(label_dict[predicted.view(label_batch.size())[i].item()]))\n",
    "      \n",
    "for i in incorrect_dict.keys():\n",
    "    print(\"Three Incorrect Predictions:\\nSentence 1: {}\\nSentence 2: {}\\n{}\\n{}\\n\".format(incorrect_dict[i][0], incorrect_dict[i][1], incorrect_dict[i][2], incorrect_dict[i][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluate on MNLI Validation Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnli_test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    for sent_1, len_1, sent_2, len_2, label, genre in loader:\n",
    "        if use_gpu:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch, genre_batch = sent_1.cuda(), len_1.cuda(), sent_2.cuda(), len_2.cuda(), label.cuda(), genre.cuda()\n",
    "        else:\n",
    "            sent_1_batch, len_1_batch, sent_2_batch, len_2_batch, label_batch, genre_batch = sent_1, len_1, sent_2, len_2, label, genre\n",
    "        outputs = F.softmax(model(sent_1_batch, len_1_batch, sent_2_batch, len_2_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        genre_acc = {}\n",
    "        for i in genre_batch.unique():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            total = genre_batch.eq(i).sum().item()\n",
    "            genre_id = genre_batch.eq(i).nonzero().view(total)\n",
    "            correct += predicted[genre_id].eq(label_batch[genre_id].view_as(predicted[genre_id])).sum().item()\n",
    "            genre_acc[genre_dict[i.item()]] = 100 * correct / total\n",
    "    return genre_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'telephone': 45.97014925373134,\n",
       " 'fiction': 43.618090452261306,\n",
       " 'slate': 41.71656686626746,\n",
       " 'government': 44.389763779527556,\n",
       " 'travel': 45.010183299389}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_test_model(mnli_val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
